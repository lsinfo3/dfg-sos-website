@article{BAUMHOER2025104495,
title = {Automated crevasse mapping for Alpine glaciers: A multitask deep neural network approach},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {139},
pages = {104495},
year = {2025},
issn = {1569-8432},
doi = {10.1016/j.jag.2025.104495},
url = {https://www.sciencedirect.com/science/article/pii/S1569843225001426},
author = {Celia A. Baumhoer and Sarah Leibrock and Caroline Zapf and Werner Beer and Claudia Kuenzer},
abstract = {Glacier crevasses are fractures in ice that form as a result of tension. Information on the location of crevasses is important for mountaineers and field researchers to plan a safe traverse over a glacier. Today, Alpine glaciers change faster than cartography can keep up with up-to-date manually created maps on crevasse zones. For the first time, this study presents an approach for automated crevasse mapping from high-resolution airborne remote sensing imagery based on a multitask deep neural network. The model was trained and evaluated over seven training and six test areas located in the Oetztal and Stubai Alps. By simultaneously preforming edge detection and segmentation tasks, the multitask model was able to robustly detect glacier crevasses of different shapes within different illumination conditions with a balanced accuracy of 86.2 %. Our approach is applicable to large-scale applications as demonstrated by creating high-resolution crevasse maps for the entire Oetztal and Stubai Alps for the years 2019/2020. Spatial and temporal transferability was proven by creating high-quality crevasse maps for all glaciers surrounding Gro√üglockner, Piz Pal√º, and Ortler. The here presented datasets can be integrated into hiking maps and digital cartography tools to provide mountaineers and field researcher with up-to-date crevasse information but also inform modelers on the distribution of stress within a glacier.}
}
@misc{sda_workflow_gruber_2025, 
    title={Settlement Delineation and Analysis}, 
    url={https://workflowhub.eu/workflows/1308?version=2}, 
    DOI={10.48546/WORKFLOWHUB.WORKFLOW.1308.2}, 
    publisher={WorkflowHub}, 
    author={Gruber, Lorenz}, 
    year={2025}
}

@misc{hossfeld_EnergyUse2025,
  author    = {Tobias Hoßfeld},
  title     = {Energy Use in Data Centers: Current Figures and Trends},
  doi       = {10.25972/OPUS-41670},
  url       = {https://opus.bibliothek.uni-wuerzburg.de/files/41670/energyUse-dataCenters-20250701.pdf},
  publisher = {ITG News 03/2025},
  month = 7,   
  pages     = {14},
  year        = {2025},
}

@Inbook{hossfeld_Scalability2025,
author="Ho{\ss}feld, Tobias
and Heegaard, Poul E.
and Kellerer, Wolfgang
and Kounev, Samuel",
title="Scalability of Networks and Systems",
bookTitle="Systems Benchmarking: For Scientists and Engineers",
year="2025",
publisher="Springer Nature Switzerland",
address="Cham",
pages="347--368",
abstract="The evaluation of communication networks and systems often mentions scalability as a key targeted property. Thus, a stringent definition of scalability and its quantification play a crucial role. In this chapter, the notion of scalability as well as the differentiation to related terms is revisited, before use case driven definitions of scalability are reviewed. The scalability index (SI) is then introduced and its application is demonstrated for the example of cloud gaming, for which two different strategies how to operate the streaming server are considered. Thereby, Quality of Experience (QoE) has manifested itself in research and industry, such that service providers can differentiate themselves by consistently delivering superior QoE compared to their competitors. The presented scalability framework allows comparing which system scales better in terms of QoE. To this end, fundamental relationships for quantifying QoE in systems are introduced. They allow measuring QoS in systems and deriving QoE metrics using appropriate mapping functions. For our use case, the average video bitrate experienced by a user is the QoS parameter, which is a main QoE influence factor. The fundamental QoE relationships allow mapping QoS to QoE metrics like Mean Opinion Scores (MOS), Good-or-Better (GoB) ratio, or Poor-or-Worse (PoW) ratio, which are discussed in the numerical results of the scalability analysis. Finally, recommendations and guidelines are provided on how to use SI in practice.",
isbn="978-3-031-85634-1",
doi="10.1007/978-3-031-85634-1_17",
url="https://doi.org/10.1007/978-3-031-85634-1_17"
}

@article{10.1145/3724501,
author = {Herbst, Nikolas and Kortmann, Mareike and Jaggy, Niklas and Thonfeld, Frank and Abad, Cristina L. and Kuenzer, Claudia and M\"{u}ller, J\"{o}rg and Kounev, Samuel},
title = {Continuous Earth Observation of Forest Dynamics and Biodiversity},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {68},
number = {7},
issn = {0001-0782},
url = {https://doi.org/10.1145/3724501},
doi = {10.1145/3724501},
abstract = {Properly managing forests requires tools that offer up-to-date information on forest dynamics.},
journal = {Commun. ACM},
month = jun,
pages = {102–107},
numpages = {6}
}

@Article{rs17162780,
AUTHOR = {Wehner, Helena and Dietz, Andreas and Kounev, Samuel and Kuenzer, Claudia},
TITLE = {Systematic Review of Satellite-Based Earth Observation Applications for Wildlife Ecology Research in Terrestrial Polar and Mountain Regions},
JOURNAL = {Remote Sensing},
VOLUME = {17},
YEAR = {2025},
NUMBER = {16},
ARTICLE-NUMBER = {2780},
URL = {https://www.mdpi.com/2072-4292/17/16/2780},
ISSN = {2072-4292},
ABSTRACT = {The extreme conditions of polar and mountain regions foster uniquely adapted wildlife. Given that climate shifts are more extreme in those regions, monitoring animal species is essential for effective conservation measures. Earth observation data offer considerable advantages in areas that are difficult to reach using traditional ground-based methods. This systematic review, based on 145 SCI-journal publications between 2000 and 2024, examines how Earth observation is used in wildlife ecology research in these regions. We give an extensive overview of the Earth observation sensors used, spatial and temporal resolution of studies, studied animal species, methods used, amount of aerial imagery linked to satellite-based Earth observation, and research objectives. Bird (52 studies) and ungulate (38 studies) species are primarily investigated in relation to animal monitoring, distribution and foraging behavior. Products of Landsat (63 studies) and MODIS (52 studies) are used in most reviewed studies, but the potential of freely available, higher spatial and temporal resolution data like Sentinel-2 (seven studies), as well as AI methods are not yet fully utilized. Linking Earth observation data in polar and mountain regions to wildlife ecology research should be facilitated by encouraging interdisciplinary working groups. Two major crises can be tackled at once, climate change and biodiversity loss.},
DOI = {10.3390/rs17162780}
}

@INPROCEEDINGS {11181478,
author = { Gruber, Lorenz and Herbst, Nikolas and Friedl, Peter and Nguyen, Thanh Thi and Esch, Thomas and Kounev, Samuel },
booktitle = { 2025 IEEE International Conference on eScience (eScience) },
title = {{ The FISHNET Case Study on Implementing and Scaling a Complex Earth Observation Workflow }},
year = {2025},
volume = {},
ISSN = {},
pages = {159-168},
abstract = { Earth observation (EO) scientists use sophisticated algorithms, large datasets, and high-performance data analytics (HPDA) clusters to develop and execute complex EO workflows. To improve portability and reusability within the domain, the Open Geospatial Consortium (OGC) published a set of best practices for developing EO workflows. Even though EO data products are often shared openly, representative EO workflow implementations are hardly available.In this paper, we contribute a case study on implementing and scaling a complex EO workflow, adhering to the OGC best practices and demonstrating its portability by deploying it both locally and on the HPDA platform "terrabyte" at the Leibniz Supercomputing Centre. Contentwise, the contributed workflow analyzes settlement patterns by first delineating coherent settlements derived from leveraged satellite data that maps builtup areas and subsequently calculating centrality measures to characterize the spatial arrangement and hierarchy of settlements in a given region.We demonstrate the workflow’s scalability and variance in resource demands by analyzing its time-to-result, total CPU time, and resource efficiency under different inputs and configurations. Interestingly, implicit parameters hidden in the input data semantics, like the number and area of settlements in the region of interest, significantly impact the time required to complete the processing. Concurrent processing is restricted to connected components of the settlement graph in the analysis stage, leading to an unbalanced workload distribution when analyzing large urban areas, showcasing the scalability challenges EO scientists face. },
keywords = {Earth;Performance evaluation;Satellites;Scalability;Urban areas;Semantics;Time measurement;Open Geospatial Consortium;Best practices;Faces},
doi = {10.1109/eScience65000.2025.00027},
url = {https://doi.ieeecomputersociety.org/10.1109/eScience65000.2025.00027},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =sep}

@inproceedings{10.1145/3676151.3719364,
author = {Rohwer, Ivo and Herbst, Nikolas and Schwinger, Maximilian and Friedl, Peter and Stephan, Michael and Kounev, Samuel},
title = {PARAGRAPH: Phase-Aware Resource Demand Profiling for HPDA/HPC Jobs},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719364},
doi = {10.1145/3676151.3719364},
abstract = {The processing of large amounts of data in central high performance data analytics (HPDA) systems is playing an increasingly important role in science and business. However, many HPDA systems exhibit a low utilization of their available resources during normal operation. An important reason for this underutilization is that too many resources are reserved for individual jobs. This is often a consequence of the common practice of reserving a uniform amount of resources such as CPU or memory for the entire execution time of a job. Given that many data intensive (DI) jobs consist of different phases with different resource demands, resources are normally reserved according to the demand of the most resource-intensive phase. This results in more resources being reserved over a long period of time than are actually needed.Flexible resource allocation techniques require detailed information about the resource demands of individual jobs to be applied effectively. In this work, we present PARAGRAPH, an approach to create phase models and resulting phase-aware resource demand profiles for individual job types from training datasets of resource consumption time series. PARAGRAPH considers the individual jobs as black boxes and fully relies on recorded system-level metrics. To do this, we first extract the different phases from the resource consumption time series using a BinSeg-based algorithm. We then apply the C-DBSCAN clustering algorithm to assign labels to the individual segments. Based on this information, a phase model and a resource demand profile can be extracted. These phase-aware resource demand profiles can then be used for scheduling decisions. We evaluate PARAGRAPH in an experimental scenario that allows flexible resource reservation on a HPDA platform. Here, we show that a given set of job instances can be executed up to 29\% faster for a given resource limit due to better resource utilization.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {3–10},
numpages = {8},
keywords = {hpc computing, phase detection, workflow profiling},
location = {Toronto ON, Canada},
series = {ICPE '25}
}
